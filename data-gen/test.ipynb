{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the TSV file into a pandas DataFrame\n",
    "input_file_path = './amazon_reviews_multilingual_US_v1_00.tsv'\n",
    "df = pd.read_csv(input_file_path, sep='\\t', on_bad_lines='skip')\n",
    "\n",
    "# Choose the column for which you want to compute statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with non-null values saved to ./big-data/data-gen/Home.csv\n",
      "Rows with non-null values saved to ./big-data/data-gen/Beauty.csv\n",
      "Rows with non-null values saved to ./big-data/data-gen/Baby.csv\n",
      "Rows with non-null values saved to ./big-data/data-gen/Apparel.csv\n",
      "Rows with non-null values saved to ./big-data/data-gen/Shoe.csv\n",
      "Rows with non-null values saved to ./big-data/data-gen/Grocery.csv\n"
     ]
    }
   ],
   "source": [
    "for category in ['Home', 'Beauty', 'Baby', 'Apparel', 'Shoe', 'Grocery']:\n",
    "    column_name = 'product_category'\n",
    "    filtered_rows = df[df[column_name] == category]\n",
    "    # unique_values = filtered_rows['product_id', 'product_title', 'product_category'].unique()\n",
    "\n",
    "    output_file_path = './big-data/data-gen/' + category + '.csv'\n",
    "    filtered_rows.to_csv(output_file_path, index=False)\n",
    "\n",
    "    print(f\"Rows with non-null values saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in product_category column:\n",
      "Books\n",
      "Music\n",
      "Video\n",
      "Video DVD\n",
      "Toys\n",
      "Tools\n",
      "Office Products\n",
      "Video Games\n",
      "Software\n",
      "Digital_Music_Purchase\n",
      "Home Entertainment\n",
      "Electronics\n",
      "Digital_Ebook_Purchase\n",
      "Digital_Video_Download\n",
      "Kitchen\n",
      "Camera\n",
      "Outdoors\n",
      "Musical Instruments\n",
      "Sports\n",
      "Watches\n",
      "PC\n",
      "Home\n",
      "Wireless\n",
      "Beauty\n",
      "Baby\n",
      "Home Improvement\n",
      "Apparel\n",
      "Shoes\n",
      "Lawn and Garden\n",
      "Mobile_Electronics\n",
      "Health & Personal Care\n",
      "Grocery\n",
      "Luggage\n",
      "Personal_Care_Appliances\n",
      "Automotive\n",
      "Mobile_Apps\n",
      "Furniture\n",
      "2012-12-22\n",
      "Pet Products\n"
     ]
    }
   ],
   "source": [
    "column_name = 'product_category'\n",
    "\n",
    "# Compute statistics for the selected column\n",
    "unique_values = df[column_name].unique()\n",
    "\n",
    "# Display the unique values\n",
    "print(f\"Unique values in {column_name} column:\")\n",
    "for value in unique_values:\n",
    "    print(value)\n",
    "\n",
    "# Filter rows with non-null values in the selected column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "1998\n",
      "        marketplace  customer_id       review_id  product_id  product_parent  \\\n",
      "493991           US     50785588  R240T6PE957SD9  B0007MWZEK        87719385   \n",
      "505034           US     41044054  R1CJU3M6FDERSO  B0007MWZEK        87719385   \n",
      "505531           US     50872012  R1GN3KRBAW4SKB  B0007MWZEK        87719385   \n",
      "507334           US     33886788  R2F5V0FE4ARXVJ  B0007MWZEK        87719385   \n",
      "516906           US     12614929  R2CY977H3JNIIF  B0007MWZEK        87719385   \n",
      "...             ...          ...             ...         ...             ...   \n",
      "6868952          US     18155497  R3D76T56CN423N  B00B2GK4KW       177865042   \n",
      "6869004          US     41316669   RGRV493DCB2IY  B00CICZ7ZQ       953405055   \n",
      "6870599          US     15619883  R2CFJ4JYSRGCWQ  B00CICZ7ZQ       953405055   \n",
      "6872319          US     38752747  R3QYVV20S0OOEV  B00CICZ7ZQ       953405055   \n",
      "6892180          US     43837412  R119A3NQBCH30O  B00CICZ7ZQ       953405055   \n",
      "\n",
      "                                             product_title product_category  \\\n",
      "493991   Cordless Swivel Sweeper – Original As Seen on ...             Home   \n",
      "505034   Cordless Swivel Sweeper – Original As Seen on ...             Home   \n",
      "505531   Cordless Swivel Sweeper – Original As Seen on ...             Home   \n",
      "507334   Cordless Swivel Sweeper – Original As Seen on ...             Home   \n",
      "516906   Cordless Swivel Sweeper – Original As Seen on ...             Home   \n",
      "...                                                    ...              ...   \n",
      "6868952  Martha Stewart Crafts Circle Edge Paper Punch ...             Home   \n",
      "6869004  Silhouette PixScan Cutting Mat for use with CAMEO             Home   \n",
      "6870599  Silhouette PixScan Cutting Mat for use with CAMEO             Home   \n",
      "6872319  Silhouette PixScan Cutting Mat for use with CAMEO             Home   \n",
      "6892180  Silhouette PixScan Cutting Mat for use with CAMEO             Home   \n",
      "\n",
      "         star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
      "493991           4.0          121.0        134.0    N                 N   \n",
      "505034           5.0           16.0         20.0    N                 Y   \n",
      "505531           5.0           15.0         17.0    N                 N   \n",
      "507334           4.0          419.0        428.0    N                 N   \n",
      "516906           2.0           35.0         36.0    N                 N   \n",
      "...              ...            ...          ...  ...               ...   \n",
      "6868952          5.0            1.0          1.0    N                 Y   \n",
      "6869004          5.0            1.0          2.0    N                 Y   \n",
      "6870599          5.0            0.0          3.0    N                 Y   \n",
      "6872319          1.0            0.0          2.0    N                 Y   \n",
      "6892180          3.0            0.0          2.0    N                 Y   \n",
      "\n",
      "                                       review_headline  \\\n",
      "493991         I'm changing my initial 4 stars to ZERO   \n",
      "505034                  Keeping the housekeeper happy.   \n",
      "505531                                        Love it!   \n",
      "507334   Decent Product but Oversold on the Commercial   \n",
      "516906                          Delayed disappointment   \n",
      "...                                                ...   \n",
      "6868952                                        Awesome   \n",
      "6869004                         Really clever product!   \n",
      "6870599                             I would recommend!   \n",
      "6872319                         Not easy to use at all   \n",
      "6892180                                    As pictured   \n",
      "\n",
      "                                               review_body review_date  \n",
      "493991   After using it maybe a total of 7 times it no ...  2005-05-19  \n",
      "505034   We have mostly wood laminate and vinyl floors ...  2005-07-03  \n",
      "505531   I was a bit skeptical about this product, but ...  2005-07-05  \n",
      "507334   Updated: January 7, 2006<br /><br />I have now...  2005-07-12  \n",
      "516906   I owned the Swivel Sweeper for 2 months before...  2005-08-16  \n",
      "...                                                    ...         ...  \n",
      "6868952  Love this! Used it for wedding invites that tu...  2015-08-26  \n",
      "6869004  Really clever product!  This is easy to use an...  2015-08-26  \n",
      "6870599                                    Loved this mat!  2015-08-26  \n",
      "6872319  This is a pain in the ass to use. Period. My p...  2015-08-27  \n",
      "6892180                     As pictured, have not used yet  2015-08-30  \n",
      "\n",
      "[1998 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "values_to_filter = ['Personal_Care_Appliances', 'Health & Personal Care', 'Beauty']\n",
    "\n",
    "# Filter rows where the specified column has values in the array\n",
    "filtered_rows = df[df[column_name] == 'Home']\n",
    "unique_values = filtered_rows[['product_id','product_title','']].unique()\n",
    "print(len(unique_values))\n",
    "# filtered_rows = df[df[column_name].isin(values_to_filter)]\n",
    "\n",
    "# Display the filtered rows\n",
    "print(len(filtered_rows))\n",
    "print((filtered_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "df_test = df[df[column_name] == '2012-12-22']\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_null_rows = df[df[column_name].notnull()]\n",
    "\n",
    "# Save the filtered rows to a new CSV file\n",
    "output_file_path = 'non_null_rows.csv'\n",
    "non_null_rows.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Rows with non-null values saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "531",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\Anaconda3-Windows\\envs\\py310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\Anaconda3-Windows\\envs\\py310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Anaconda3-Windows\\envs\\py310\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 531",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\TestBigData\\big-data\\data-gen\\test.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/TestBigData/big-data/data-gen/test.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m product_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m./product.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/TestBigData/big-data/data-gen/test.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m index \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mrandrange(\u001b[39mlen\u001b[39m(product_df))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/TestBigData/big-data/data-gen/test.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m product \u001b[39m=\u001b[39m product_df[index]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/TestBigData/big-data/data-gen/test.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(product)\n",
      "File \u001b[1;32md:\\Anaconda3-Windows\\envs\\py310\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\Anaconda3-Windows\\envs\\py310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 531"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "product_df = pd.read_csv(\"./product.csv\")\n",
    "index = random.randrange(len(product_df))\n",
    "product = product_df[index]\n",
    "print(product)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
